{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84eeb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cda823d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dhira\\\\Desktop\\\\MLflow\\\\MLflow-DVC\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a91d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e3aaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dhira\\\\Desktop\\\\MLflow\\\\MLflow-DVC'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7acf70e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"DhirajRouniyar/MLflow-DVC\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"DhirajRouniyar/MLflow-DVC\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository DhirajRouniyar/MLflow-DVC initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository DhirajRouniyar/MLflow-DVC initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='DhirajRouniyar', repo_name='MLflow-DVC', mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "with mlflow.start_run():\n",
    "  mlflow.log_param('parameter name', 'value')\n",
    "  mlflow.log_metric('metric name', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c74276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  # allow duplicate OpenMP runtime\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e85b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhira\\AppData\\Local\\Temp\\ipykernel_20300\\3757099262.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"artifacts/training/model.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=25088, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Recreate the same model architecture\n",
    "model = models.vgg16(weights=None)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512*7*7, 2)  # must match your original model\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load weights\n",
    "model.load_state_dict(torch.load(\"artifacts/training/model.pt\", map_location=device))\n",
    "model.eval()  # for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9651f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entity\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen = True)\n",
    "class EvaluationConfig:\n",
    "    path_to_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    params_classes: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03048873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b510149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Update the configuration manager in src config\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_to_model=\"artifacts/training/model.pt\",\n",
    "            training_data=\"artifacts/data_ingestion/kidney-ct-scan-image\",\n",
    "            mlflow_uri=\"DVC.mlflow\",\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE,\n",
    "            params_classes = self.params.CLASSES\n",
    "        )\n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dcdbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig, device=None):\n",
    "        self.config = config\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = None\n",
    "        self.valid_loader = None\n",
    "        self.score = None\n",
    "        self.avg_loss = None\n",
    "        self.accuracy = None\n",
    "\n",
    "    def _valid_loader(self):\n",
    "        \"\"\"Create validation DataLoader with split=0.3\"\"\"\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(self.config.params_image_size[:2]),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        full_dataset = datasets.ImageFolder(\n",
    "            root=self.config.training_data,\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "        valid_size = int(0.3 * len(full_dataset))\n",
    "        train_size = len(full_dataset) - valid_size\n",
    "        _, valid_dataset = random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "        self.valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path: Path, num_classes: int, device=\"cpu\"):\n",
    "        \"\"\"Recreate architecture and load trained weights\"\"\"\n",
    "        model = models.vgg16(weights=None)\n",
    "        in_features = 512 * 7 * 7\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def evaluation(self):\n",
    "        \"\"\"Run evaluation and save score\"\"\"\n",
    "        self.model = self.load_model(\n",
    "            path=self.config.path_to_model,\n",
    "            num_classes=self.config.params_classes,\n",
    "            device=self.device\n",
    "        )\n",
    "        self._valid_loader()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.valid_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        self.avg_loss = total_loss / total\n",
    "        self.accuracy = correct / total\n",
    "        self.score = (self.avg_loss, self.accuracy)\n",
    "        self.save_score()\n",
    "\n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "        with open(\"scores.json\", \"w\") as f:\n",
    "            json.dump(scores, f, indent=4)\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "       # Connect to DagsHub MLflow\n",
    "        dagshub.init(repo_owner=\"DhirajRouniyar\", repo_name=\"MLflow-DVC\", mlflow=True)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics({\n",
    "                \"loss\": self.avg_loss,\n",
    "                \"accuracy\": self.accuracy\n",
    "            })\n",
    "\n",
    "            # Log model to DagsHub\n",
    "            mlflow.pytorch.log_model(self.model, \"model\", registered_model_name=\"TorchModel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dff1d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 00:00:14,705: INFO: common: yaml_file: config\\config.yaml loaded successfully]\n",
      "[2025-09-10 00:00:14,706: INFO: common: yaml_file: params.yaml loaded successfully]\n",
      "[2025-09-10 00:00:14,706: INFO: common: created directory at: artifacts]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhira\\AppData\\Local\\Temp\\ipykernel_20300\\1977927998.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 00:00:17,876: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/DhirajRouniyar/MLflow-DVC \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"DhirajRouniyar/MLflow-DVC\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"DhirajRouniyar/MLflow-DVC\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 00:00:17,889: INFO: helpers: Initialized MLflow to track repo \"DhirajRouniyar/MLflow-DVC\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository DhirajRouniyar/MLflow-DVC initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository DhirajRouniyar/MLflow-DVC initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 00:00:17,889: INFO: helpers: Repository DhirajRouniyar/MLflow-DVC initialized!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhira\\miniconda3\\envs\\MLflow\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Registered model 'TorchModel' already exists. Creating a new version of this model...\n",
      "2025/09/10 00:01:00 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: TorchModel, version 2\n",
      "Created version '2' of model 'TorchModel'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_evaluation_config()\n",
    "    evaluation = Evaluation(eval_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "   raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
